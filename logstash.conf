# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
  }
}

filter {
  csv {
    separator => ","
    columns => ["Timestamp","PreciseTimeStamp","ServicePrefix","Region","GatewayId","Tenant","Role","RoleInstance","ResourceId","operationName","time","category","properties","RowKey","__SourceEvent__","__SourceMoniker__","timeStamp"]
    remove_field => ["message", "PreciseTimeStamp","ServicePrefix","GatewayId","Role","RoleInstance","operationName","time","category","RowKey","__SourceEvent__","__SourceMoniker__","timeStamp"]
    remove_field => ["source", "offset", "host", "tags", "prospector", "beat", "input"]
  }
}

output {
  stdout { codec => rubydebug }
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
}
